{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c8044fe",
   "metadata": {},
   "source": [
    "# Player Snapshot Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0bc441",
   "metadata": {},
   "source": [
    "依照 `feature_engineering_idea.md` 的設計，把 Transfermarkt 原始 csv 壓成單一的玩家 snapshot table。每個 row 代表 `(player_id, snapshot_date)` 的狀態，所有特徵都只依賴當下時間點之前的資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5d06e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/wuyusen/Desktop/Northwestern MLDS/2025 MLDS Hackathon/hackathon-2025-evan-ston-energy\n",
      "Output path: /Users/wuyusen/Desktop/Northwestern MLDS/2025 MLDS Hackathon/hackathon-2025-evan-ston-energy/data/processed/player_snapshot_features.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', 120)\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "override_root = os.environ.get('PROJECT_ROOT_OVERRIDE')\n",
    "if override_root:\n",
    "    PROJECT_ROOT = Path(override_root)\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "OUTPUT_DIR = DATA_DIR / 'processed'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_PATH = OUTPUT_DIR / 'player_snapshot_features.csv'\n",
    "\n",
    "print(f'Project root: {PROJECT_ROOT}')\n",
    "print(f'Output path: {OUTPUT_PATH}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d37d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for value parsing and rolling window aggregations.\n",
    "def parse_euro_value(value: str) -> float:\n",
    "    \"\"\"Normalize Transfermarkt value strings (e.g. '+€3.05m') into floats.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    text = str(value).strip()\n",
    "    if not text:\n",
    "        return np.nan\n",
    "    text = text.replace('€', '').replace(',', '').replace('+', '').strip()\n",
    "    if text in {'', '-'}:\n",
    "        return np.nan\n",
    "    multiplier = 1.0\n",
    "    lower = text.lower()\n",
    "    if lower.endswith('bn'):\n",
    "        multiplier = 1e9\n",
    "        text = text[:-2]\n",
    "    elif lower.endswith('m'):\n",
    "        multiplier = 1e6\n",
    "        text = text[:-1]\n",
    "    elif lower.endswith('k'):\n",
    "        multiplier = 1e3\n",
    "        text = text[:-1]\n",
    "    cleaned = re.sub(r'[^0-9.\\-]', '', text)\n",
    "    if cleaned in {'', '-'}:\n",
    "        return np.nan\n",
    "    return float(cleaned) * multiplier\n",
    "\n",
    "\n",
    "def compute_cumulative_table(df, entity_col, date_col, aggregations):\n",
    "    \"\"\"Aggregate metrics per day and build cumulative sums for merge_asof windows.\"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[entity_col, date_col]), []\n",
    "    working = df.dropna(subset=[entity_col, date_col]).copy()\n",
    "    working[date_col] = pd.to_datetime(working[date_col])\n",
    "    named_aggs = {\n",
    "        feature_name: pd.NamedAgg(column=source_col, aggfunc=agg_func)\n",
    "        for feature_name, (source_col, agg_func) in aggregations.items()\n",
    "    }\n",
    "    grouped = (\n",
    "        working.sort_values([entity_col, date_col])\n",
    "        .groupby([entity_col, date_col], as_index=False)\n",
    "        .agg(**named_aggs)\n",
    "    )\n",
    "    cumulative_cols = []\n",
    "    for feature_name in aggregations.keys():\n",
    "        cum_col = f'cum_{feature_name}'\n",
    "        grouped[cum_col] = grouped.groupby(entity_col)[feature_name].cumsum()\n",
    "        cumulative_cols.append(cum_col)\n",
    "    return grouped[[entity_col, date_col] + cumulative_cols], cumulative_cols\n",
    "\n",
    "\n",
    "def window_aggregate(\n",
    "    base_df,\n",
    "    cumulative_df,\n",
    "    base_entity_col,\n",
    "    base_date_col,\n",
    "    entity_col,\n",
    "    date_col,\n",
    "    cumulative_cols,\n",
    "    window_days,\n",
    "    prefix,\n",
    "    offset_days=0,\n",
    "):\n",
    "    \"\"\"Vectorized rolling window lookup using numpy searchsorted per entity.\"\"\"\n",
    "    if cumulative_df.empty or not cumulative_cols:\n",
    "        return pd.DataFrame(index=base_df.index)\n",
    "\n",
    "    temp = base_df[[base_entity_col, base_date_col]].copy()\n",
    "    temp = temp.dropna(subset=[base_date_col]).copy()\n",
    "    temp = temp.reset_index().rename(columns={'index': '__row_id'})\n",
    "    temp['__entity_key'] = temp[base_entity_col].fillna(-1).astype(float)\n",
    "    temp['__target_date'] = pd.to_datetime(temp[base_date_col]) - pd.to_timedelta(offset_days, unit='D')\n",
    "\n",
    "    cumulative_sorted = cumulative_df.dropna(subset=[entity_col, date_col]).copy()\n",
    "    cumulative_sorted['__entity_key'] = cumulative_sorted[entity_col].fillna(-1).astype(float)\n",
    "    cumulative_sorted = cumulative_sorted.sort_values([ '__entity_key', date_col ])\n",
    "\n",
    "    chunks = []\n",
    "    for entity_key, group in temp.groupby('__entity_key'):\n",
    "        left = group.sort_values('__target_date')\n",
    "        right = cumulative_sorted[cumulative_sorted['__entity_key'] == entity_key]\n",
    "        if right.empty:\n",
    "            merged_recent = left[['__row_id']].copy()\n",
    "            merged_window = left[['__row_id']].copy()\n",
    "            for col in cumulative_cols:\n",
    "                merged_recent[col] = 0.0\n",
    "                merged_window[col] = 0.0\n",
    "        else:\n",
    "            right_dates = right[date_col].to_numpy()\n",
    "            target_recent = left['__target_date'].to_numpy()\n",
    "            idx_recent = np.searchsorted(right_dates, target_recent, side='right') - 1\n",
    "            idx_recent[idx_recent < 0] = -1\n",
    "            window_delta = np.timedelta64(window_days, 'D')\n",
    "            target_window = target_recent - window_delta\n",
    "            idx_window = np.searchsorted(right_dates, target_window, side='right') - 1\n",
    "            idx_window[idx_window < 0] = -1\n",
    "            merged_recent = left[['__row_id']].copy()\n",
    "            merged_window = left[['__row_id']].copy()\n",
    "            for col in cumulative_cols:\n",
    "                values = right[col].to_numpy()\n",
    "                merged_recent[col] = np.where(idx_recent >= 0, values[idx_recent], 0.0)\n",
    "                merged_window[col] = np.where(idx_window >= 0, values[idx_window], 0.0)\n",
    "        chunk = merged_recent[['__row_id']].copy()\n",
    "        for col in cumulative_cols:\n",
    "            metric_name = col.replace('cum_', '')\n",
    "            chunk[f'{prefix}{metric_name}'] = merged_recent[col].astype(float) - merged_window[col].astype(float)\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    features = pd.concat(chunks, ignore_index=True)\n",
    "    return features.set_index('__row_id').sort_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def safe_per_90(numerator, minutes):\n",
    "    \"\"\"Return per-90 values that gracefully handle players with limited minutes.\"\"\"\n",
    "    numerator = numerator.astype(float)\n",
    "    minutes = minutes.astype(float)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        per90 = np.where(minutes > 0, numerator / minutes * 90.0, 0.0)\n",
    "    return per90\n",
    "\n",
    "\n",
    "def compute_linear_momentum(group, window_days):\n",
    "    \"\"\"Fit a simple slope of MV trend inside the specified window.\"\"\"\n",
    "    group = group.sort_values('snapshot_date')\n",
    "    slopes = []\n",
    "    for idx, row in group.iterrows():\n",
    "        window_start = row['snapshot_date'] - pd.to_timedelta(window_days, unit='D')\n",
    "        subset = group[\n",
    "            (group['snapshot_date'] > window_start)\n",
    "            & (group['snapshot_date'] <= row['snapshot_date'])\n",
    "        ]\n",
    "        if subset.shape[0] >= 2:\n",
    "            x = (subset['snapshot_date'] - subset['snapshot_date'].min()).dt.days.astype(float)\n",
    "            y = subset['current_market_value'].values\n",
    "            slope = np.polyfit(x, y, 1)[0]\n",
    "        else:\n",
    "            slope = np.nan\n",
    "        slopes.append(slope)\n",
    "    return pd.Series(slopes, index=group.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6274f751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Players: (32601, 23), Valuations: (496606, 5), Appearances: (1706806, 13)\n"
     ]
    }
   ],
   "source": [
    "# Load raw CSV files from the data directory.\n",
    "players = pd.read_csv(\n",
    "    DATA_DIR / 'players.csv',\n",
    "    parse_dates=['date_of_birth', 'contract_expiration_date'],\n",
    ")\n",
    "valuations = pd.read_csv(\n",
    "    DATA_DIR / 'player_valuations.csv',\n",
    "    parse_dates=['date'],\n",
    ")\n",
    "appearances = pd.read_csv(\n",
    "    DATA_DIR / 'appearances.csv',\n",
    "    parse_dates=['date'],\n",
    ")\n",
    "games = pd.read_csv(\n",
    "    DATA_DIR / 'games.csv',\n",
    "    parse_dates=['date'],\n",
    ")\n",
    "club_games = pd.read_csv(DATA_DIR / 'club_games.csv')\n",
    "clubs = pd.read_csv(DATA_DIR / 'clubs.csv')\n",
    "competitions = pd.read_csv(DATA_DIR / 'competitions.csv')\n",
    "game_events = pd.read_csv(\n",
    "    DATA_DIR / 'game_events.csv',\n",
    "    parse_dates=['date'],\n",
    ")\n",
    "game_lineups = pd.read_csv(\n",
    "    DATA_DIR / 'game_lineups.csv',\n",
    "    parse_dates=['date'],\n",
    ")\n",
    "transfers = pd.read_csv(\n",
    "    DATA_DIR / 'transfers.csv',\n",
    "    parse_dates=['transfer_date'],\n",
    ")\n",
    "\n",
    "print(f'Players: {players.shape}, Valuations: {valuations.shape}, Appearances: {appearances.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfd71f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning for numeric columns and helper references.\n",
    "numeric_cols = ['goals', 'assists', 'minutes_played', 'yellow_cards', 'red_cards']\n",
    "for col in numeric_cols:\n",
    "    appearances[col] = pd.to_numeric(appearances[col], errors='coerce').fillna(0)\n",
    "appearances['game_id'] = pd.to_numeric(appearances['game_id'], errors='coerce')\n",
    "\n",
    "club_games = club_games.merge(games[['game_id', 'date']], on='game_id', how='left')\n",
    "club_games['date'] = pd.to_datetime(club_games['date'])\n",
    "club_games['own_goals'] = pd.to_numeric(club_games['own_goals'], errors='coerce').fillna(0)\n",
    "club_games['opponent_goals'] = pd.to_numeric(club_games['opponent_goals'], errors='coerce').fillna(0)\n",
    "club_games['is_win'] = pd.to_numeric(club_games['is_win'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "clubs['club_total_market_value'] = clubs['total_market_value'].apply(parse_euro_value)\n",
    "clubs['club_net_transfer_record'] = clubs['net_transfer_record'].apply(parse_euro_value)\n",
    "for col in ['squad_size', 'average_age', 'foreigners_percentage', 'national_team_players']:\n",
    "    clubs[col] = pd.to_numeric(clubs[col], errors='coerce')\n",
    "\n",
    "competitions['is_major_national_league'] = (\n",
    "    competitions['is_major_national_league'].astype(str).str.lower() == 'true'\n",
    ")\n",
    "\n",
    "game_events['player_id'] = pd.to_numeric(game_events['player_id'], errors='coerce')\n",
    "game_events['player_assist_id'] = pd.to_numeric(game_events['player_assist_id'], errors='coerce')\n",
    "\n",
    "game_lineups['player_id'] = pd.to_numeric(game_lineups['player_id'], errors='coerce')\n",
    "\n",
    "transfers['transfer_fee'] = pd.to_numeric(transfers['transfer_fee'], errors='coerce')\n",
    "transfers['market_value_in_eur'] = pd.to_numeric(transfers['market_value_in_eur'], errors='coerce')\n",
    "transfers['from_club_id'] = pd.to_numeric(transfers['from_club_id'], errors='coerce')\n",
    "transfers['to_club_id'] = pd.to_numeric(transfers['to_club_id'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the valuation-driven snapshot table.\n",
    "snapshots = valuations.rename(\n",
    "    columns={'date': 'snapshot_date', 'market_value_in_eur': 'current_market_value'}\n",
    ").copy()\n",
    "snapshots = snapshots.sort_values(['player_id', 'snapshot_date']).reset_index(drop=True)\n",
    "\n",
    "player_cols = [\n",
    "    'player_id',\n",
    "    'name',\n",
    "    'date_of_birth',\n",
    "    'sub_position',\n",
    "    'position',\n",
    "    'foot',\n",
    "    'height_in_cm',\n",
    "    'contract_expiration_date',\n",
    "    'country_of_birth',\n",
    "    'country_of_citizenship',\n",
    "    'current_club_name',\n",
    "]\n",
    "snapshots = snapshots.merge(players[player_cols], on='player_id', how='left')\n",
    "snapshots['player_name'] = snapshots['name']\n",
    "snapshots['age'] = (\n",
    "    (snapshots['snapshot_date'] - snapshots['date_of_birth']).dt.days / 365.25\n",
    ")\n",
    "snapshots['years_to_contract_end'] = (\n",
    "    (snapshots['contract_expiration_date'] - snapshots['snapshot_date']).dt.days / 365.25\n",
    ")\n",
    "snapshots['season'] = snapshots['snapshot_date'].dt.year\n",
    "\n",
    "club_cols = [\n",
    "    'club_id',\n",
    "    'club_total_market_value',\n",
    "    'squad_size',\n",
    "    'average_age',\n",
    "    'foreigners_percentage',\n",
    "    'national_team_players',\n",
    "]\n",
    "snapshots = snapshots.merge(\n",
    "    clubs[club_cols],\n",
    "    left_on='current_club_id',\n",
    "    right_on='club_id',\n",
    "    how='left',\n",
    ").drop(columns=['club_id'])\n",
    "\n",
    "competition_cols = ['competition_id', 'name', 'type', 'country_name', 'is_major_national_league']\n",
    "snapshots = snapshots.merge(\n",
    "    competitions[competition_cols],\n",
    "    left_on='player_club_domestic_competition_id',\n",
    "    right_on='competition_id',\n",
    "    how='left',\n",
    ")\n",
    "snapshots = snapshots.rename(\n",
    "    columns={\n",
    "        'name': 'competition_name',\n",
    "        'type': 'competition_type',\n",
    "        'country_name': 'competition_country',\n",
    "    }\n",
    ")\n",
    "\n",
    "top5_codes = {'ES1', 'GB1', 'IT1', 'L1', 'FR1'}\n",
    "snapshots['is_top5_league'] = snapshots['player_club_domestic_competition_id'].isin(top5_codes).astype(int)\n",
    "snapshots['league_strength'] = np.select(\n",
    "    [snapshots['is_top5_league'] == 1, snapshots['is_major_national_league'] == True],\n",
    "    [3, 2],\n",
    "    default=1,\n",
    ")\n",
    "\n",
    "snapshots['highest_market_value_to_date'] = snapshots.groupby('player_id')['current_market_value'].cummax()\n",
    "snapshots['mv_ratio_to_peak'] = np.where(\n",
    "    snapshots['highest_market_value_to_date'] > 0,\n",
    "    snapshots['current_market_value'] / snapshots['highest_market_value_to_date'],\n",
    "    np.nan,\n",
    ")\n",
    "\n",
    "rolling_counts = (\n",
    "    snapshots.set_index('snapshot_date')\n",
    "    .groupby('player_id')['current_market_value']\n",
    "    .rolling('365D')\n",
    "    .count()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "snapshots['num_valuations_365'] = rolling_counts.values\n",
    "\n",
    "for window_days, col_name in [(180, 'mv_momentum_6m'), (365, 'mv_momentum_12m')]:\n",
    "    snapshots[col_name] = (\n",
    "        snapshots.groupby('player_id', group_keys=False)\n",
    "        .apply(lambda grp: compute_linear_momentum(grp, window_days))\n",
    "        .values\n",
    "    )\n",
    "\n",
    "snapshots.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d61b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance features from appearances (365d + previous 365d).\n",
    "appearance_metrics = appearances[[\n",
    "    'player_id',\n",
    "    'date',\n",
    "    'minutes_played',\n",
    "    'goals',\n",
    "    'assists',\n",
    "    'yellow_cards',\n",
    "    'red_cards',\n",
    "    'game_id',\n",
    "]].dropna(subset=['player_id'])\n",
    "appearance_aggs = {\n",
    "    'minutes_total': ('minutes_played', 'sum'),\n",
    "    'goals_total': ('goals', 'sum'),\n",
    "    'assists_total': ('assists', 'sum'),\n",
    "    'yellow_cards_total': ('yellow_cards', 'sum'),\n",
    "    'red_cards_total': ('red_cards', 'sum'),\n",
    "    'games_played': ('game_id', 'count'),\n",
    "}\n",
    "appearance_cum, appearance_cols = compute_cumulative_table(\n",
    "    appearance_metrics,\n",
    "    'player_id',\n",
    "    'date',\n",
    "    appearance_aggs,\n",
    ")\n",
    "last365 = window_aggregate(\n",
    "    snapshots,\n",
    "    appearance_cum,\n",
    "    'player_id',\n",
    "    'snapshot_date',\n",
    "    'player_id',\n",
    "    'date',\n",
    "    appearance_cols,\n",
    "    365,\n",
    "    'last365_',\n",
    ")\n",
    "prev365 = window_aggregate(\n",
    "    snapshots,\n",
    "    appearance_cum,\n",
    "    'player_id',\n",
    "    'snapshot_date',\n",
    "    'player_id',\n",
    "    'date',\n",
    "    appearance_cols,\n",
    "    365,\n",
    "    'prev365_',\n",
    "    offset_days=365,\n",
    ")\n",
    "snapshots = snapshots.join(last365).join(prev365)\n",
    "\n",
    "rename_map = {\n",
    "    'last365_minutes_total': 'minutes_total_365',\n",
    "    'last365_goals_total': 'goals_total_365',\n",
    "    'last365_assists_total': 'assists_total_365',\n",
    "    'last365_yellow_cards_total': 'yellow_cards_total_365',\n",
    "    'last365_red_cards_total': 'red_cards_total_365',\n",
    "    'last365_games_played': 'games_played_365',\n",
    "    'prev365_minutes_total': 'prev_minutes_total_365',\n",
    "    'prev365_goals_total': 'prev_goals_total_365',\n",
    "    'prev365_assists_total': 'prev_assists_total_365',\n",
    "    'prev365_yellow_cards_total': 'prev_yellow_cards_total_365',\n",
    "    'prev365_red_cards_total': 'prev_red_cards_total_365',\n",
    "    'prev365_games_played': 'prev_games_played_365',\n",
    "}\n",
    "snapshots = snapshots.rename(columns=rename_map)\n",
    "\n",
    "snapshots['minutes_per_game_365'] = np.where(\n",
    "    snapshots['games_played_365'] > 0,\n",
    "    snapshots['minutes_total_365'] / snapshots['games_played_365'],\n",
    "    np.nan,\n",
    ")\n",
    "snapshots['goals_per_90_365'] = safe_per_90(\n",
    "    snapshots['goals_total_365'], snapshots['minutes_total_365']\n",
    ")\n",
    "snapshots['assists_per_90_365'] = safe_per_90(\n",
    "    snapshots['assists_total_365'], snapshots['minutes_total_365']\n",
    ")\n",
    "snapshots['goal_contributions_per_90_365'] = safe_per_90(\n",
    "    snapshots['goals_total_365'] + snapshots['assists_total_365'],\n",
    "    snapshots['minutes_total_365'],\n",
    ")\n",
    "snapshots['discipline_cards_per_90_365'] = safe_per_90(\n",
    "    snapshots['yellow_cards_total_365'] + snapshots['red_cards_total_365'],\n",
    "    snapshots['minutes_total_365'],\n",
    ")\n",
    "snapshots['prev_goals_per_90_365'] = safe_per_90(\n",
    "    snapshots['prev_goals_total_365'], snapshots['prev_minutes_total_365']\n",
    ")\n",
    "snapshots['prev_assists_per_90_365'] = safe_per_90(\n",
    "    snapshots['prev_assists_total_365'], snapshots['prev_minutes_total_365']\n",
    ")\n",
    "snapshots['delta_minutes_total'] = snapshots['minutes_total_365'] - snapshots['prev_minutes_total_365']\n",
    "snapshots['delta_goals_per_90'] = snapshots['goals_per_90_365'] - snapshots['prev_goals_per_90_365']\n",
    "snapshots['delta_assists_per_90'] = snapshots['assists_per_90_365'] - snapshots['prev_assists_per_90_365']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0906a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Availability & starter rate features using game_lineups.\n",
    "lineups = game_lineups[['player_id', 'date', 'type']].dropna(subset=['player_id']).copy()\n",
    "lineups['is_start'] = (lineups['type'] == 'starting_lineup').astype(int)\n",
    "lineups['in_match_squad'] = 1\n",
    "lineup_aggs = {\n",
    "    'starts_total': ('is_start', 'sum'),\n",
    "    'squad_inclusions': ('in_match_squad', 'sum'),\n",
    "}\n",
    "lineup_cum, lineup_cols = compute_cumulative_table(\n",
    "    lineups,\n",
    "    'player_id',\n",
    "    'date',\n",
    "    lineup_aggs,\n",
    ")\n",
    "lineup_window = window_aggregate(\n",
    "    snapshots,\n",
    "    lineup_cum,\n",
    "    'player_id',\n",
    "    'snapshot_date',\n",
    "    'player_id',\n",
    "    'date',\n",
    "    lineup_cols,\n",
    "    365,\n",
    "    'lineup365_',\n",
    ")\n",
    "snapshots = snapshots.join(lineup_window)\n",
    "snapshots = snapshots.rename(\n",
    "    columns={\n",
    "        'lineup365_starts_total': 'starts_365',\n",
    "        'lineup365_squad_inclusions': 'squad_inclusions_365',\n",
    "    }\n",
    ")\n",
    "snapshots['starter_rate_365'] = np.where(\n",
    "    snapshots['squad_inclusions_365'] > 0,\n",
    "    snapshots['starts_365'] / snapshots['squad_inclusions_365'],\n",
    "    np.nan,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84066ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event-level context: goals, cards, substitutions.\n",
    "events = game_events.dropna(subset=['player_id', 'date']).copy()\n",
    "events['is_goal_event'] = (events['type'] == 'Goals').astype(int)\n",
    "events['is_card_event'] = (events['type'] == 'Cards').astype(int)\n",
    "events['is_sub_event'] = (events['type'] == 'Substitutions').astype(int)\n",
    "events['is_assist_event'] = (events['player_assist_id'] == events['player_id']).astype(int)\n",
    "event_aggs = {\n",
    "    'goal_events': ('is_goal_event', 'sum'),\n",
    "    'card_events': ('is_card_event', 'sum'),\n",
    "    'substitution_events': ('is_sub_event', 'sum'),\n",
    "    'assist_events': ('is_assist_event', 'sum'),\n",
    "}\n",
    "event_cum, event_cols = compute_cumulative_table(\n",
    "    events,\n",
    "    'player_id',\n",
    "    'date',\n",
    "    event_aggs,\n",
    ")\n",
    "event_window = window_aggregate(\n",
    "    snapshots,\n",
    "    event_cum,\n",
    "    'player_id',\n",
    "    'snapshot_date',\n",
    "    'player_id',\n",
    "    'date',\n",
    "    event_cols,\n",
    "    365,\n",
    "    'events365_',\n",
    ")\n",
    "snapshots = snapshots.join(event_window)\n",
    "snapshots = snapshots.rename(\n",
    "    columns={\n",
    "        'events365_goal_events': 'goal_events_365',\n",
    "        'events365_card_events': 'card_events_365',\n",
    "        'events365_substitution_events': 'substitution_events_365',\n",
    "        'events365_assist_events': 'assist_events_365',\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46693309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Club form context (wins, goal difference, etc.).\n",
    "club_games_subset = club_games[[\n",
    "    'club_id',\n",
    "    'date',\n",
    "    'game_id',\n",
    "    'is_win',\n",
    "    'own_goals',\n",
    "    'opponent_goals',\n",
    "]].dropna(subset=['club_id', 'date']).copy()\n",
    "club_aggs = {\n",
    "    'club_games_total': ('game_id', 'count'),\n",
    "    'club_wins_total': ('is_win', 'sum'),\n",
    "    'club_goals_for_total': ('own_goals', 'sum'),\n",
    "    'club_goals_against_total': ('opponent_goals', 'sum'),\n",
    "}\n",
    "club_cum, club_cols = compute_cumulative_table(\n",
    "    club_games_subset,\n",
    "    'club_id',\n",
    "    'date',\n",
    "    club_aggs,\n",
    ")\n",
    "club_window = window_aggregate(\n",
    "    snapshots,\n",
    "    club_cum,\n",
    "    'current_club_id',\n",
    "    'snapshot_date',\n",
    "    'club_id',\n",
    "    'date',\n",
    "    club_cols,\n",
    "    365,\n",
    "    'club365_',\n",
    ")\n",
    "snapshots = snapshots.join(club_window)\n",
    "snapshots = snapshots.rename(\n",
    "    columns={\n",
    "        'club365_club_games_total': 'club_games_365',\n",
    "        'club365_club_wins_total': 'club_wins_365',\n",
    "        'club365_club_goals_for_total': 'club_goals_for_365',\n",
    "        'club365_club_goals_against_total': 'club_goals_against_365',\n",
    "    }\n",
    ")\n",
    "snapshots['club_win_rate_365'] = np.where(\n",
    "    snapshots['club_games_365'] > 0,\n",
    "    snapshots['club_wins_365'] / snapshots['club_games_365'],\n",
    "    np.nan,\n",
    ")\n",
    "snapshots['club_goal_diff_365'] = snapshots['club_goals_for_365'] - snapshots['club_goals_against_365']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a2d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer history signals (recent transfer, fee delta, etc.).\n",
    "transfer_context = transfers.dropna(subset=['player_id', 'transfer_date']).copy()\n",
    "transfer_context = transfer_context.sort_values(['player_id', 'transfer_date'])\n",
    "transfer_context = transfer_context.merge(\n",
    "    clubs[['club_id', 'club_total_market_value']].rename(\n",
    "        columns={'club_id': 'from_club_id', 'club_total_market_value': 'from_club_value'}\n",
    "    ),\n",
    "    on='from_club_id',\n",
    "    how='left',\n",
    ")\n",
    "transfer_context = transfer_context.merge(\n",
    "    clubs[['club_id', 'club_total_market_value']].rename(\n",
    "        columns={'club_id': 'to_club_id', 'club_total_market_value': 'to_club_value'}\n",
    "    ),\n",
    "    on='to_club_id',\n",
    "    how='left',\n",
    ")\n",
    "transfer_subset = transfer_context[[\n",
    "    'player_id',\n",
    "    'transfer_date',\n",
    "    'transfer_fee',\n",
    "    'market_value_in_eur',\n",
    "    'from_club_value',\n",
    "    'to_club_value',\n",
    "]]\n",
    "\n",
    "snapshots_sorted = snapshots.sort_values(['player_id', 'snapshot_date']).reset_index()\n",
    "transfer_chunks = []\n",
    "for player_id, snap_group in snapshots_sorted.groupby('player_id'):\n",
    "    chunk = snap_group[['index', 'snapshot_date']].copy()\n",
    "    player_transfers = transfer_subset[transfer_subset['player_id'] == player_id]\n",
    "    if player_transfers.empty:\n",
    "        chunk['transfer_date'] = pd.NaT\n",
    "        chunk['transfer_fee'] = np.nan\n",
    "        chunk['market_value_in_eur'] = np.nan\n",
    "        chunk['from_club_value'] = np.nan\n",
    "        chunk['to_club_value'] = np.nan\n",
    "    else:\n",
    "        trans_dates = player_transfers['transfer_date'].to_numpy()\n",
    "        snap_dates = snap_group['snapshot_date'].to_numpy()\n",
    "        idx = np.searchsorted(trans_dates, snap_dates, side='right') - 1\n",
    "        mask = idx >= 0\n",
    "        idx_safe = idx.copy()\n",
    "        idx_safe[~mask] = 0\n",
    "        values_date = player_transfers['transfer_date'].to_numpy()\n",
    "        values_fee = player_transfers['transfer_fee'].to_numpy()\n",
    "        values_mv = player_transfers['market_value_in_eur'].to_numpy()\n",
    "        values_from = player_transfers['from_club_value'].to_numpy()\n",
    "        values_to = player_transfers['to_club_value'].to_numpy()\n",
    "        chunk['transfer_date'] = pd.to_datetime(\n",
    "            np.where(mask, values_date[idx_safe], np.datetime64('NaT'))\n",
    "        )\n",
    "        chunk['transfer_fee'] = np.where(mask, values_fee[idx_safe], np.nan)\n",
    "        chunk['market_value_in_eur'] = np.where(mask, values_mv[idx_safe], np.nan)\n",
    "        chunk['from_club_value'] = np.where(mask, values_from[idx_safe], np.nan)\n",
    "        chunk['to_club_value'] = np.where(mask, values_to[idx_safe], np.nan)\n",
    "    transfer_chunks.append(chunk)\n",
    "\n",
    "transfer_features = pd.concat(transfer_chunks, ignore_index=True)\n",
    "transfer_features['days_since_last_transfer'] = (\n",
    "    transfer_features['snapshot_date'] - transfer_features['transfer_date']\n",
    ").dt.days\n",
    "transfer_features['has_recent_transfer'] = transfer_features['days_since_last_transfer'].between(0, 365, inclusive='both')\n",
    "transfer_features['moved_to_bigger_club'] = np.where(\n",
    "    transfer_features['has_recent_transfer']\n",
    "    & (transfer_features['to_club_value'] > transfer_features['from_club_value']),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "transfer_features['transfer_fee_vs_mv'] = (\n",
    "    transfer_features['transfer_fee'] - transfer_features['market_value_in_eur']\n",
    ")\n",
    "transfer_df = transfer_features.set_index('index')[[\n",
    "    'has_recent_transfer',\n",
    "    'moved_to_bigger_club',\n",
    "    'transfer_fee_vs_mv',\n",
    "    'days_since_last_transfer',\n",
    "]]\n",
    "snapshots = snapshots.join(transfer_df, how='left')\n",
    "snapshots['has_recent_transfer'] = snapshots['has_recent_transfer'].fillna(0).astype(int)\n",
    "snapshots['moved_to_bigger_club'] = snapshots['moved_to_bigger_club'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d892f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final feature table export.\n",
    "feature_columns = [\n",
    "    'player_id',\n",
    "    'player_name',\n",
    "    'snapshot_date',\n",
    "    'season',\n",
    "    'age',\n",
    "    'position',\n",
    "    'sub_position',\n",
    "    'foot',\n",
    "    'height_in_cm',\n",
    "    'country_of_birth',\n",
    "    'country_of_citizenship',\n",
    "    'current_club_id',\n",
    "    'current_club_name',\n",
    "    'player_club_domestic_competition_id',\n",
    "    'competition_name',\n",
    "    'competition_country',\n",
    "    'competition_type',\n",
    "    'league_strength',\n",
    "    'is_top5_league',\n",
    "    'club_total_market_value',\n",
    "    'squad_size',\n",
    "    'average_age',\n",
    "    'foreigners_percentage',\n",
    "    'national_team_players',\n",
    "    'current_market_value',\n",
    "    'highest_market_value_to_date',\n",
    "    'mv_ratio_to_peak',\n",
    "    'mv_momentum_6m',\n",
    "    'mv_momentum_12m',\n",
    "    'num_valuations_365',\n",
    "    'years_to_contract_end',\n",
    "    'minutes_total_365',\n",
    "    'games_played_365',\n",
    "    'goals_total_365',\n",
    "    'assists_total_365',\n",
    "    'yellow_cards_total_365',\n",
    "    'red_cards_total_365',\n",
    "    'minutes_per_game_365',\n",
    "    'goals_per_90_365',\n",
    "    'assists_per_90_365',\n",
    "    'goal_contributions_per_90_365',\n",
    "    'discipline_cards_per_90_365',\n",
    "    'prev_minutes_total_365',\n",
    "    'prev_goals_total_365',\n",
    "    'prev_assists_total_365',\n",
    "    'prev_goals_per_90_365',\n",
    "    'prev_assists_per_90_365',\n",
    "    'delta_minutes_total',\n",
    "    'delta_goals_per_90',\n",
    "    'delta_assists_per_90',\n",
    "    'starts_365',\n",
    "    'squad_inclusions_365',\n",
    "    'starter_rate_365',\n",
    "    'goal_events_365',\n",
    "    'card_events_365',\n",
    "    'substitution_events_365',\n",
    "    'assist_events_365',\n",
    "    'club_games_365',\n",
    "    'club_wins_365',\n",
    "    'club_goals_for_365',\n",
    "    'club_goals_against_365',\n",
    "    'club_win_rate_365',\n",
    "    'club_goal_diff_365',\n",
    "    'has_recent_transfer',\n",
    "    'moved_to_bigger_club',\n",
    "    'transfer_fee_vs_mv',\n",
    "    'days_since_last_transfer',\n",
    "]\n",
    "final_df = snapshots[feature_columns].sort_values(['snapshot_date', 'player_id']).reset_index(drop=True)\n",
    "final_df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f'Saved {len(final_df):,} rows with {final_df.shape[1]} columns to {OUTPUT_PATH}')\n",
    "final_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
